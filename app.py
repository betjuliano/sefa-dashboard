
import os
import io
import json
from datetime import datetime

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
import statsmodels.api as sm
from scipy import stats
from scipy.stats import chi2_contingency, pearsonr, spearmanr

from dotenv import load_dotenv

# ===== NOVO SISTEMA DE PROCESSAMENTO =====
from app_integration import (
    app_integration,
    update_global_variables as new_update_global_variables,
    filter_by_question_set as new_filter_by_question_set,
    compute_metrics as new_compute_metrics,
    normalize_likert as new_normalize_likert,
    normalize_satisfaction as new_normalize_satisfaction,
    add_sidebar_enhancements
)
# ==========================================


# Supabase removido - usando apenas armazenamento local

load_dotenv()

st.set_page_config(
    page_title="Dashboard de Qualidade - MVP",
    page_icon="üìä",
    layout="wide",
)

# -----------------------------
# Utils
# Load configuration
@st.cache_resource
def load_mapping(path: str):
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def get_mapping_for_question_set(question_set: str):
    """Get the appropriate mapping based on question set"""
    if question_set == "8 quest√µes":
        return load_mapping(os.path.join("config", "items_mapping_8q.json"))
    else:
        return load_mapping(os.path.join("config", "items_mapping.json"))

def update_global_variables(question_set: str):
    """Atualiza as vari√°veis globais baseado no conjunto de quest√µes selecionado - NOVO SISTEMA"""
    # Usar o novo sistema integrado
    new_update_global_variables(question_set)

# Initialize with default mapping (will be updated based on question set)
MAPPING = load_mapping(os.path.join("config", "items_mapping.json"))

DIMENSIONS = MAPPING["dimensions"]
LIKERT_ORDER = MAPPING["likert_order"]
LIKERT_MAP = {k: v for k, v in MAPPING["likert_map"].items()}
SAT_FIELD = MAPPING["satisfaction_field"]
SAT_MAP = MAPPING["satisfaction_map"]
PROFILE_FIELDS = MAPPING["profile_fields"]

DEFAULT_GOAL = float(os.getenv("DEFAULT_GOAL", "4.0"))

# Sistema usando apenas armazenamento local

# Session state
from core.data_manager import DataManager
# Remover import de UserPreferences
# from core.models import UserPreferences

if "auth" not in st.session_state:
    st.session_state.auth = {"email": None, "logged_in": False}
if "uploads" not in st.session_state:
    st.session_state.uploads = []  # fallback if Supabase is not used
if "dm" not in st.session_state:
    st.session_state.dm = DataManager()

# -----------------------------
# Auth (simplified; Supabase optional)
# -----------------------------
def login_ui():
    st.sidebar.subheader("Login / Registro")
    email = st.sidebar.text_input("E-mail")
    password = st.sidebar.text_input("Senha", type="password")

    col1, col2 = st.sidebar.columns(2)
    if col1.button("Entrar"):
        try:
            ok = st.session_state.dm.authenticate_user(email, password)
            if ok:
                st.session_state.auth = {"email": email, "logged_in": True}
                st.sidebar.success("Login realizado")
                st.rerun()
            else:
                st.sidebar.error("Credenciais inv√°lidas.")
        except Exception as e:
            st.sidebar.error(f"Falha no login: {e}")

    if col2.button("Registrar"):
        st.sidebar.info("Registro indispon√≠vel no modo demo. Use qualquer email/senha em 'Entrar'.")

def logout_btn():
    if st.sidebar.button("üö™ Logout"):
        st.session_state.auth = {"email": None, "logged_in": False}
        st.rerun()

# -----------------------------
# Data processing
# -----------------------------
def normalize_likert(series: pd.Series) -> pd.Series:
    """Normaliza escala Likert - NOVO SISTEMA"""
    # Usar o novo ScaleConverter
    return new_normalize_likert(series)

def normalize_satisfaction(series: pd.Series) -> pd.Series:
    """Normaliza escala de satisfa√ß√£o - NOVO SISTEMA"""
    # Usar o novo ScaleConverter
    return new_normalize_satisfaction(series)

def show_preprocessed_stats(df: pd.DataFrame):
    """Exibe estat√≠sticas dos dados pr√©-processados se dispon√≠veis"""
    if 'Media_Respostas' in df.columns and 'Num_Respostas_Validas' in df.columns:
        st.subheader("üìä Estat√≠sticas dos Dados Pr√©-processados")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("M√©dia Geral", f"{df['Media_Respostas'].mean():.2f}")
            st.metric("Mediana", f"{df['Media_Respostas'].median():.2f}")
        
        with col2:
            st.metric("Desvio Padr√£o", f"{df['Media_Respostas'].std():.2f}")
            st.metric("Amplitude", f"{df['Media_Respostas'].max() - df['Media_Respostas'].min():.2f}")
        
        with col3:
            st.metric("Valor M√≠nimo", f"{df['Media_Respostas'].min():.2f}")
            st.metric("Valor M√°ximo", f"{df['Media_Respostas'].max():.2f}")
        
        # Distribui√ß√£o de respostas v√°lidas
        st.subheader("üìà Distribui√ß√£o de Respostas V√°lidas por Linha")
        valid_counts = df['Num_Respostas_Validas'].value_counts().sort_index()
        
        col1, col2 = st.columns(2)
        with col1:
            for count, freq in valid_counts.items():
                st.write(f"**{count} respostas:** {freq} linhas ({freq/len(df)*100:.1f}%)")
        
        with col2:
            # Gr√°fico de barras da distribui√ß√£o
            import plotly.express as px
            fig = px.bar(
                x=valid_counts.index, 
                y=valid_counts.values,
                labels={'x': 'N√∫mero de Respostas V√°lidas', 'y': 'Frequ√™ncia'},
                title="Distribui√ß√£o de Respostas V√°lidas"
            )
            st.plotly_chart(fig, use_container_width=True)

def compute_metrics(df: pd.DataFrame, goal: float):
    """Calcula m√©tricas do question√°rio - NOVO SISTEMA"""
    # Usar o novo sistema integrado
    return new_compute_metrics(df, goal)


def prepare_data_for_analysis(df: pd.DataFrame):
    """Prepare data for statistical analysis"""
    df_analysis = df.copy()
    
    # Convert Likert scales to numeric
    for dim_name, items in DIMENSIONS.items():
        for item in items:
            if item in df_analysis.columns:
                df_analysis[item] = normalize_likert(df_analysis[item])
    
    # Convert satisfaction to numeric
    if SAT_FIELD in df_analysis.columns:
        df_analysis[SAT_FIELD] = normalize_satisfaction(df_analysis[SAT_FIELD])
    
    # Create dimension scores (mean of items in each dimension)
    print(f"DEBUG: DIMENSIONS = {DIMENSIONS}")
    print(f"DEBUG: df_analysis.columns = {list(df_analysis.columns)}")
    
    for dim_name, items in DIMENSIONS.items():
        available_items = [item for item in items if item in df_analysis.columns]
        print(f"DEBUG: For dimension '{dim_name}', items = {items}")
        print(f"DEBUG: Available items = {available_items}")
        if available_items:
            df_analysis[f'{dim_name}_score'] = df_analysis[available_items].mean(axis=1)
            print(f"DEBUG: Created score column '{dim_name}_score'")
        else:
            print(f"DEBUG: No available items for dimension '{dim_name}'")
    
    print(f"DEBUG: Final columns after score creation = {list(df_analysis.columns)}")
    
    # Encode categorical variables
    le_sexo = LabelEncoder()
    le_escolaridade = LabelEncoder()
    le_servidor = LabelEncoder()
    
    if PROFILE_FIELDS["Sexo"] in df_analysis.columns:
        df_analysis['sexo_encoded'] = le_sexo.fit_transform(df_analysis[PROFILE_FIELDS["Sexo"]].fillna('N√£o informado'))
    
    if PROFILE_FIELDS["Escolaridade"] in df_analysis.columns:
        df_analysis['escolaridade_encoded'] = le_escolaridade.fit_transform(df_analysis[PROFILE_FIELDS["Escolaridade"]].fillna('N√£o informado'))
    
    # Handle different field names for public servant field
    servidor_field = PROFILE_FIELDS.get("Servidor P√∫blico") or PROFILE_FIELDS.get("Funcionario_Publico")
    if servidor_field and servidor_field in df_analysis.columns:
        df_analysis['servidor_encoded'] = le_servidor.fit_transform(df_analysis[servidor_field].fillna('N√£o informado'))
    
    return df_analysis

def regression_analysis(df: pd.DataFrame, target_dimension: str):
    """Perform regression analysis for a dimension"""
    df_clean = df.dropna(subset=[f'{target_dimension}_score'])
    
    # Prepare features
    features = []
    feature_names = []
    
    if 'idade_encoded' in df_clean.columns:
        features.append(df_clean[PROFILE_FIELDS["Idade"]].fillna(df_clean[PROFILE_FIELDS["Idade"]].median()))
        feature_names.append('Idade')
    
    if 'sexo_encoded' in df_clean.columns:
        features.append(df_clean['sexo_encoded'])
        feature_names.append('Sexo')
    
    if 'escolaridade_encoded' in df_clean.columns:
        features.append(df_clean['escolaridade_encoded'])
        feature_names.append('Escolaridade')
    
    if 'servidor_encoded' in df_clean.columns:
        features.append(df_clean['servidor_encoded'])
        feature_names.append('Servidor P√∫blico')
    
    if SAT_FIELD in df_clean.columns:
        features.append(df_clean[SAT_FIELD].fillna(df_clean[SAT_FIELD].median()))
        feature_names.append('Satisfa√ß√£o Geral')
    
    if not features:
        return None, None
    
    X = np.column_stack(features)
    y = df_clean[f'{target_dimension}_score']
    
    # Remove rows with NaN
    mask = ~(np.isnan(X).any(axis=1) | np.isnan(y))
    X = X[mask]
    y = y[mask]
    
    if len(X) < 10:  # Need minimum samples
        return None, None
    
    # OLS Regression
    X_with_const = sm.add_constant(X)
    model = sm.OLS(y, X_with_const).fit()
    
    return model, feature_names

def multivariate_analysis(df: pd.DataFrame):
    """Perform multivariate analysis"""
    # Prepare data
    dimension_scores = []
    dimension_names = []
    
    for dim_name in DIMENSIONS.keys():
        if f'{dim_name}_score' in df.columns:
            dimension_scores.append(df[f'{dim_name}_score'].fillna(df[f'{dim_name}_score'].median()))
            dimension_names.append(dim_name)
    
    if len(dimension_scores) < 2:
        return None
    
    X = np.column_stack(dimension_scores)
    
    # Remove rows with NaN
    mask = ~np.isnan(X).any(axis=1)
    X = X[mask]
    
    if len(X) < 10:
        return None
    
    # Standardize data
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # PCA Analysis
    pca = PCA()
    pca_result = pca.fit_transform(X_scaled)
    
    # Determine optimal number of clusters
    silhouette_scores = []
    K_range = range(2, min(8, len(X)//10 + 1))
    
    for k in K_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(X_scaled)
        silhouette_avg = silhouette_score(X_scaled, cluster_labels)
        silhouette_scores.append(silhouette_avg)
    
    optimal_k = K_range[np.argmax(silhouette_scores)] if silhouette_scores else 2
    
    # Final clustering
    kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
    cluster_labels = kmeans_final.fit_predict(X_scaled)
    
    return {
        'pca': pca,
        'pca_result': pca_result,
        'scaler': scaler,
        'kmeans': kmeans_final,
        'cluster_labels': cluster_labels,
        'dimension_names': dimension_names,
        'optimal_k': optimal_k,
        'silhouette_scores': silhouette_scores,
        'X_scaled': X_scaled
    }

def filters_ui(df: pd.DataFrame):
    st.sidebar.markdown("### Filtros")
    df_filtered = df.copy()

    # carregar filtros salvos, se houver
    saved = {}
    if st.session_state.auth["logged_in"]:
        try:
            p = st.session_state.dm.get_user_preferences(st.session_state.auth["email"]) 
            saved = p.get("saved_filters", {}) if isinstance(p, dict) else {}
        except Exception:
            saved = {}

    # Idade
    if PROFILE_FIELDS["Idade"] in df.columns:
        # Verificar se h√° dados v√°lidos na coluna de idade
        idade_col = df[PROFILE_FIELDS["Idade"]]
        idade_valida = idade_col.dropna()
        
        if len(idade_valida) > 0:
            # Tentar converter valores para num√©rico se poss√≠vel
            try:
                # Se os valores s√£o strings como "25-34 anos", extrair o primeiro n√∫mero
                idade_numerica = []
                for val in idade_valida:
                    if isinstance(val, str):
                        # Extrair n√∫meros da string (ex: "25-34 anos" -> 25)
                        import re
                        numeros = re.findall(r'\d+', str(val))
                        if numeros:
                            idade_numerica.append(int(numeros[0]))
                    elif pd.notna(val):
                        try:
                            idade_numerica.append(int(float(val)))
                        except:
                            pass
                
                if idade_numerica:
                    min_age = min(idade_numerica)
                    max_age = max(idade_numerica)
                    default_age = tuple(saved.get("idade", (min_age, max_age)))
                    age_min, age_max = st.sidebar.slider("Idade", min_value=min_age, max_value=max_age, value=default_age)
                    
                    # Filtrar baseado nos valores originais
                    mask_idade = pd.Series([True] * len(df_filtered))
                    for idx, val in enumerate(df_filtered[PROFILE_FIELDS["Idade"]]):
                        if pd.notna(val):
                            if isinstance(val, str):
                                numeros = re.findall(r'\d+', str(val))
                                if numeros:
                                    idade_num = int(numeros[0])
                                    mask_idade.iloc[idx] = age_min <= idade_num <= age_max
                            else:
                                try:
                                    idade_num = int(float(val))
                                    mask_idade.iloc[idx] = age_min <= idade_num <= age_max
                                except:
                                    pass
                    
                    df_filtered = df_filtered[mask_idade]
                else:
                    st.sidebar.info("‚ö†Ô∏è Dados de idade n√£o dispon√≠veis para filtro")
            except Exception as e:
                st.sidebar.warning(f"‚ö†Ô∏è Erro ao processar dados de idade: {str(e)}")
        else:
            st.sidebar.info("‚ö†Ô∏è Dados de idade n√£o dispon√≠veis para filtro")

    # Sexo
    if PROFILE_FIELDS["Sexo"] in df.columns:
        sex_opts = ["Todos"] + sorted([x for x in df[PROFILE_FIELDS["Sexo"]].dropna().unique().tolist()])
        default_sex = saved.get("sexo", "Todos")
        sex_sel = st.sidebar.selectbox("Sexo", options=sex_opts, index=sex_opts.index(default_sex) if default_sex in sex_opts else 0)
        if sex_sel != "Todos":
            df_filtered = df_filtered[df_filtered[PROFILE_FIELDS["Sexo"]] == sex_sel]

    # Escolaridade
    if PROFILE_FIELDS["Escolaridade"] in df.columns:
        esc_opts = ["Todos"] + sorted([x for x in df[PROFILE_FIELDS["Escolaridade"]].dropna().unique().tolist()])
        default_esc = saved.get("escolaridade", "Todos")
        esc_sel = st.sidebar.selectbox("Escolaridade", options=esc_opts, index=esc_opts.index(default_esc) if default_esc in esc_opts else 0)
        if esc_sel != "Todos":
            df_filtered = df_filtered[df_filtered[PROFILE_FIELDS["Escolaridade"]] == esc_sel]

    # Servidor P√∫blico
    servidor_field = PROFILE_FIELDS.get("Servidor P√∫blico") or PROFILE_FIELDS.get("Funcionario_Publico")
    if servidor_field and servidor_field in df.columns:
        sp_opts = ["Todos"] + sorted([x for x in df[servidor_field].dropna().unique().tolist()])
        default_sp = saved.get("servidor_publico", "Todos")
        sp_sel = st.sidebar.selectbox("Servidor P√∫blico", options=sp_opts, index=sp_opts.index(default_sp) if default_sp in sp_opts else 0)
        if sp_sel != "Todos":
            df_filtered = df_filtered[df_filtered[servidor_field] == sp_sel]

    # salvar filtros atualizados, se logado
    if st.session_state.auth["logged_in"]:
        try:
            current = st.session_state.dm.get_user_preferences(st.session_state.auth["email"]) 
            new_saved = {
                "idade": (age_min, age_max) if PROFILE_FIELDS["Idade"] in df.columns else saved.get("idade"),
                "sexo": sex_sel if PROFILE_FIELDS["Sexo"] in df.columns else saved.get("sexo"),
                "escolaridade": esc_sel if PROFILE_FIELDS["Escolaridade"] in df.columns else saved.get("escolaridade"),
                "servidor_publico": sp_sel if servidor_field and servidor_field in df.columns else saved.get("servidor_publico"),
            }
            updated = dict(current or {}) if isinstance(current, dict) else {}
            updated["saved_filters"] = new_saved
            st.session_state.dm.save_user_preferences(st.session_state.auth["email"], updated)
        except Exception:
            pass

    return df_filtered

# -----------------------------
# UI: Sidebar
# -----------------------------
st.sidebar.title("üìä Dashboard de Qualidade")
if not st.session_state.auth["logged_in"]:
    login_ui()
else:
    st.sidebar.success(f"Logado como: {st.session_state.auth['email']}")
    logout_btn()

# goal persistente por usu√°rio (se logado)
if st.session_state.auth["logged_in"]:
    prefs = st.session_state.dm.get_user_preferences(st.session_state.auth["email"])  # dict
    goal_default = float(prefs.get("goal", prefs.get("goal_global", DEFAULT_GOAL)))
else:
    prefs = None
    goal_default = DEFAULT_GOAL

goal = st.sidebar.number_input("Meta (1 a 5)", min_value=1.0, max_value=5.0, value=goal_default, step=0.1)
# Se usu√°rio alterar a meta e estiver logado, salvar
if st.session_state.auth["logged_in"] and abs(goal - goal_default) > 1e-9:
    new_prefs = dict(prefs or {})
    new_prefs["goal"] = float(goal)
    st.session_state.dm.save_user_preferences(st.session_state.auth["email"], new_prefs)

st.sidebar.markdown("---")

# Seletor de conjunto de quest√µes
if "question_set" not in st.session_state:
    st.session_state.question_set = "Completo (26 quest√µes)"

question_set = st.sidebar.radio(
    "Conjunto de Quest√µes",
    options=["Completo (26 quest√µes)", "20 quest√µes", "8 quest√µes"],
    index=["Completo (26 quest√µes)", "20 quest√µes", "8 quest√µes"].index(st.session_state.question_set)
)

# Atualizar vari√°veis globais se o conjunto mudou
if question_set != st.session_state.question_set:
    update_global_variables(question_set)
    
st.session_state.question_set = question_set

# Adicionar melhorias do novo sistema
add_sidebar_enhancements()

# Upload espec√≠fico para 8 quest√µes
if question_set == "8 quest√µes":
    uploaded_8q = st.sidebar.file_uploader(
        "Upload base 8 quest√µes (opcional)",
        type=["csv"],
        key="upload_8q"
    )
    if uploaded_8q:
        st.session_state.uploaded_8q = uploaded_8q
        st.session_state.data_8q_source = uploaded_8q.name
    else:
        st.session_state.uploaded_8q = None
        st.session_state.data_8q_source = "basetransp.csv (padr√£o)"

st.sidebar.markdown("---")
st.sidebar.caption("CSV padr√£o: separador `;` e codifica√ß√£o `latin-1`.")

# -----------------------------
# Main Pages
# -----------------------------
pages = {
    "Dashboard": "dashboard",
    "Portal Transpar√™ncia": "portal_transparencia",
    "Upload de Arquivo": "upload",
    "An√°lise Detalhada": "analysis",
    "Perfil": "profile",
    "Configura√ß√µes": "settings",
}
page = st.sidebar.radio("Navega√ß√£o", options=list(pages.keys()))

# -----------------------------
# Question Set Filtering
# -----------------------------
def filter_by_question_set(df: pd.DataFrame, question_set: str):
    """Filtra o dataframe baseado no conjunto de quest√µes selecionado - NOVO SISTEMA"""
    # Usar o novo sistema integrado
    return new_filter_by_question_set(df, question_set)


def read_csv(uploaded_file, delimiter=";", encoding="latin-1"):
    return pd.read_csv(uploaded_file, sep=delimiter, encoding=encoding)

def data_source_ui():
    st.markdown("#### Fonte de Dados")
    
    # Mostrar fonte atual
    if st.session_state.data is not None:
        st.info(f"üìä **Dados atuais:** {st.session_state.data_source}")
        st.caption(f"Linhas: {len(st.session_state.data)}, Colunas: {len(st.session_state.data.columns)}")
    
    st.markdown("#### Upload de Novo Arquivo")
    uploaded = st.file_uploader("Carregue um arquivo .csv para substituir os dados atuais", type=["csv"])
    col_delim, col_enc = st.columns(2)
    delimiter = col_delim.selectbox("Delimitador", options=[";", ",", "\\t"], index=0)
    enc = col_enc.selectbox("Codifica√ß√£o", options=["latin-1", "utf-8"], index=0)

    if uploaded is not None:
        try:
            df = read_csv(uploaded, delimiter=delimiter.replace("\\t", "\t"), encoding=enc)
            return df, uploaded.name
        except Exception as e:
            st.error(f"Erro ao ler CSV: {e}")

    # Bot√µes para restaurar dados padr√£o
    st.markdown("#### Restaurar Dados Padr√£o")
    st.caption("Escolha qual conjunto de dados padr√£o deseja carregar")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("üîÑ Restaurar baseKelm.csv\n(Completo - 20 quest√µes)", use_container_width=True):
            try:
                df = read_csv(os.path.join("sample_data", "baseKelm.csv"))
                # Automaticamente definir para "20 quest√µes" para aplicar filtro
                st.session_state.question_set = "20 quest√µes"
                return df, "baseKelm.csv (restaurado)"
            except Exception as e:
                st.error(f"Erro ao carregar baseKelm.csv: {e}")
    
    with col2:
        if st.button("üîÑ Restaurar basetransp.csv\n(8 quest√µes)", use_container_width=True):
            try:
                df = read_csv(os.path.join("data", "basetransp.csv"))
                # Automaticamente definir para "8 quest√µes"
                st.session_state.question_set = "8 quest√µes"
                return df, "basetransp.csv (restaurado)"
            except Exception as e:
                st.error(f"Erro ao carregar basetransp.csv: {e}")
    return None, None

# -----------------------------
# Page: Upload
# -----------------------------
if page == "Upload de Arquivo":
    st.header("üì§ Upload de Arquivo")
    df, fname = data_source_ui()
    if df is not None:
        st.success(f"Arquivo carregado: **{fname}** ‚Äî linhas: {len(df)}, colunas: {len(df.columns)}")
        st.dataframe(df.head(10))

        # Save to session
        st.session_state.data = df
        st.session_state.data_source = fname

        # Log upload via DataManager (local storage, substitui anteriores)
        if st.session_state.auth["logged_in"]:
            try:
                rec = st.session_state.dm.save_upload(st.session_state.auth["email"], df, fname)
                # manter um pequeno resumo na sess√£o para UI r√°pida
                st.session_state.uploads = [{
                    "user_email": rec.user_email,
                    "filename": rec.filename,
                    "n_rows": rec.n_rows,
                    "n_cols": rec.n_cols,
                    "uploaded_at": rec.uploaded_at.isoformat()
                }]
            except Exception as e:
                st.warning(f"N√£o foi poss√≠vel registrar upload localmente: {e}")
        
        # For√ßar rerun para atualizar a interface
        st.rerun()

# -----------------------------
# Page: Dashboard
# -----------------------------
if page == "Dashboard":
    st.header("üè† Vis√£o Geral")
    if st.session_state.data is None:
        st.info("Carregue um CSV na p√°gina **Upload de Arquivo** ou use o dado de exemplo.")
    else:
        # Mostrar fonte dos dados no dashboard
        st.info(f"üìä **Analisando dados de:** {st.session_state.data_source} | Conjunto: {st.session_state.question_set}")
        df = st.session_state.data.copy()
        # Aplicar filtro de conjunto de quest√µes
        df = filter_by_question_set(df, st.session_state.question_set)
        
        # Exibir estat√≠sticas dos dados pr√©-processados se dispon√≠veis
        if st.session_state.question_set == "8 quest√µes":
            show_preprocessed_stats(df)
        
        df_f = filters_ui(df)

        metrics = compute_metrics(df_f, goal)

        cols = st.columns(4)
        cols[0].metric("N respostas (filtrado)", len(df_f))
        cols[1].metric("Meta (goal)", f"{goal:.1f}")
        if metrics["satisfaction"] is not None:
            cols[2].metric("Satisfa√ß√£o m√©dia", f"{metrics['satisfaction']:.2f}")
        cols[3].metric("Dimens√µes", len(DIMENSIONS))

        # Radar chart of dimensions
        st.subheader("Radar por Dimens√£o")
        r_vals = [metrics["dimensions"][d]["mean"] if metrics["dimensions"][d]["mean"] is not None else 0 for d in DIMENSIONS.keys()]
        radar_cat = list(DIMENSIONS.keys())
        fig = go.Figure()
        fig.add_trace(go.Scatterpolar(r=r_vals, theta=radar_cat, fill="toself", name="M√©dia"))
        fig.update_layout(
            polar=dict(radialaxis=dict(
                visible=True, 
                range=[1, 5],
                tickvals=[1, 2, 3, 4, 5],
                ticktext=['1', '2', '3', '4', '5']
            )),
            showlegend=False,
            height=450,
        )
        st.plotly_chart(fig, use_container_width=True)

        # ===== Novo layout de Insights =====
        # CSS moderno para badges e cards
        st.markdown(
            """
            <style>
            /* Vari√°veis CSS para tema moderno */
            :root {
                --primary-blue: #2563eb;
                --primary-blue-light: #3b82f6;
                --success-green: #10b981;
                --warning-orange: #f59e0b;
                --danger-red: #ef4444;
                --neutral-50: #f8fafc;
                --neutral-100: #f1f5f9;
                --neutral-200: #e2e8f0;
                --neutral-300: #cbd5e1;
                --neutral-400: #94a3b8;
                --neutral-500: #64748b;
                --neutral-600: #475569;
                --neutral-700: #334155;
                --neutral-800: #1e293b;
                --neutral-900: #0f172a;
                --shadow-sm: 0 1px 2px 0 rgb(0 0 0 / 0.05);
                --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
                --shadow-lg: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1);
                --border-radius: 12px;
                --border-radius-sm: 8px;
            }
            
            .badge { 
                display: inline-block; 
                padding: 4px 12px; 
                border-radius: 20px; 
                font-size: 12px; 
                font-weight: 600;
                color: #ffffff; 
                margin-left: 8px;
                text-transform: uppercase;
                letter-spacing: 0.5px;
                box-shadow: var(--shadow-sm);
            }
            .badge-green { 
                background: linear-gradient(135deg, var(--success-green), #059669);
                border: 1px solid rgba(16, 185, 129, 0.2);
            }
            .badge-orange { 
                background: linear-gradient(135deg, var(--warning-orange), #d97706);
                border: 1px solid rgba(245, 158, 11, 0.2);
            }
            .badge-red { 
                background: linear-gradient(135deg, var(--danger-red), #dc2626);
                border: 1px solid rgba(239, 68, 68, 0.2);
            }
            
            .card { 
                border: 1px solid var(--neutral-200); 
                border-radius: var(--border-radius); 
                padding: 20px 24px; 
                background: linear-gradient(135deg, #ffffff, var(--neutral-50));
                margin-bottom: 16px;
                box-shadow: var(--shadow-md);
                transition: all 0.3s ease;
                position: relative;
                overflow: hidden;
            }
            .card:hover {
                transform: translateY(-2px);
                box-shadow: var(--shadow-lg);
                border-color: var(--primary-blue-light);
            }
            .card::before {
                content: '';
                position: absolute;
                top: 0;
                left: 0;
                right: 0;
                height: 3px;
                background: linear-gradient(90deg, var(--primary-blue), var(--primary-blue-light));
                border-radius: var(--border-radius) var(--border-radius) 0 0;
            }
            
            .item-row { 
                display: flex; 
                align-items: center; 
                justify-content: space-between; 
                gap: 12px;
                margin-bottom: 8px;
            }
            .item-name { 
                font-size: 0.95rem; 
                font-weight: 500;
                color: var(--neutral-700);
                line-height: 1.4;
            }
            .item-mean { 
                font-weight: 700; 
                font-size: 1.1rem;
                color: var(--neutral-800);
                background: var(--neutral-100);
                padding: 4px 8px;
                border-radius: var(--border-radius-sm);
                min-width: 50px;
                text-align: center;
            }
            .small { 
                font-size: 0.875rem; 
                color: var(--neutral-500);
                font-weight: 500;
                margin-bottom: 12px;
            }
            
            .dot { 
                display: inline-block; 
                width: 12px; 
                height: 12px; 
                border-radius: 50%; 
                margin-left: 8px; 
                vertical-align: middle;
                box-shadow: var(--shadow-sm);
                border: 2px solid #ffffff;
            }
            
            .progress-bar {
                height: 8px;
                background: var(--neutral-200);
                border-radius: 4px;
                overflow: hidden;
                margin: 8px 0;
                box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
            }
            .progress-fill {
                height: 100%;
                border-radius: 4px;
                transition: width 0.3s ease;
                background: linear-gradient(90deg, var(--primary-blue), var(--primary-blue-light));
            }
            .progress-fill.green {
                background: linear-gradient(90deg, var(--success-green), #059669);
            }
            .progress-fill.orange {
                background: linear-gradient(90deg, var(--warning-orange), #d97706);
            }
            .progress-fill.red {
                background: linear-gradient(90deg, var(--danger-red), #dc2626);
            }
            
            .sugg { 
                color: var(--neutral-600); 
                font-size: 0.875rem; 
                margin-top: 8px;
                line-height: 1.5;
                background: var(--neutral-50);
                padding: 8px 12px;
                border-radius: var(--border-radius-sm);
                border-left: 3px solid var(--primary-blue-light);
            }
            .sugg i { 
                color: var(--warning-orange);
                margin-right: 6px;
            }
            
            /* Status indicators */
            .status-excellent { color: var(--success-green); }
            .status-good { color: var(--warning-orange); }
            .status-poor { color: var(--danger-red); }
            
            /* Alert styling */
            .alert-warning {
                background: linear-gradient(135deg, #fef3c7, #fde68a);
                border: 1px solid #f59e0b;
                border-radius: var(--border-radius);
                padding: 16px 20px;
                margin: 16px 0;
                color: var(--neutral-800);
                font-weight: 500;
            }
            
            /* Tab styling */
            .stTabs [data-baseweb="tab-list"] {
                gap: 8px;
            }
            .stTabs [data-baseweb="tab"] {
                background: var(--neutral-100);
                border-radius: var(--border-radius-sm);
                padding: 8px 16px;
                font-weight: 500;
                transition: all 0.3s ease;
            }
            .stTabs [aria-selected="true"] {
                background: var(--primary-blue);
                color: white;
                box-shadow: var(--shadow-sm);
            }
            </style>
            """,
            unsafe_allow_html=True,
        )
        
        # Linha de aten√ß√£o
        pri, aco, bons = metrics["insights"]["criticos"], metrics["insights"]["acoes"], metrics["insights"]["bons"]
        all_items_stats = []
        for dim_name, its in DIMENSIONS.items():
            for it in its:
                if it in metrics["items"]:
                    all_items_stats.append((it, dim_name, metrics["items"][it]["mean"]))
        if all_items_stats:
            worst_item, worst_dim, worst_mean = min(all_items_stats, key=lambda x: x[2])
            gap = float(goal) - float(worst_mean)
            gap_txt = f"(gap {gap:.2f})" if gap > 0 else ""
            st.markdown(
                f"""
                <div class="alert-warning">
                    <strong>‚ö†Ô∏è Aten√ß√£o:</strong> {len(pri)+len(aco)} itens abaixo da meta ‚Äî {len(pri)} cr√≠ticos. 
                    <br><strong>Pior desempenho:</strong> [{worst_dim}] {worst_item} com m√©dia {worst_mean:.2f} {gap_txt}.
                </div>
                """,
                unsafe_allow_html=True
            )
        
        st.subheader("Insights Autom√°ticos")
        
        tab_overview, tab_list, tab_corr = st.tabs(["Vis√£o geral", "Lista completa", "A√ß√µes coordenadas"]) 
        
        # --- Aba: Vis√£o Geral (cart√µes por dimens√£o com 2 itens de menor m√©dia) ---
        with tab_overview:
            cols_dim = st.columns(3)
            for idx, dim_name in enumerate(DIMENSIONS.keys()):
                with cols_dim[idx % 3]:
                    dim_mean = metrics["dimensions"][dim_name]["mean"] if dim_name in metrics["dimensions"] else None
                    # meta por dimens√£o (se existir)
                    try:
                        dim_goal = float((prefs or {}).get("goal_by_dimension", {}).get(dim_name, goal)) if isinstance(prefs, dict) else float(goal)
                    except Exception:
                        dim_goal = float(goal)
                    # farol
                    color = "#10b981" if (dim_mean is not None and dim_mean >= dim_goal) else ("#f59e0b" if (dim_mean is not None and dim_goal - dim_mean <= 0.5) else "#ef4444")
                    status_class = "status-excellent" if (dim_mean is not None and dim_mean >= dim_goal) else ("status-good" if (dim_mean is not None and dim_goal - dim_mean <= 0.5) else "status-poor")
                    st.markdown(
                        f"<div class='card'>"
                        f"<div class='item-row'><strong>{dim_name}</strong>"
                        f"<span class='dot' style='background:{color}'></span></div>"
                        f"<div class='small'>M√©dia <span class='{status_class}'>{(dim_mean if dim_mean is not None else 0):.2f}</span> / Meta {dim_goal:.1f}</div>",
                        unsafe_allow_html=True,
                    )
                    # 2 itens com menor m√©dia da dimens√£o
                    it_means = [(it, metrics["items"][it]["mean"]) for it in DIMENSIONS[dim_name] if it in metrics["items"]]
                    it_means.sort(key=lambda x: (x[1] is None, x[1]))
                    lows = it_means[:2] if len(it_means) >= 2 else it_means
                    for it, mean in lows:
                        pct = 0.0
                        try:
                            pct = max(0.0, min(1.0, float(mean) / 5.0))
                        except Exception:
                            pct = 0.0
                        
                        # Determinar classe da barra de progresso
                        progress_class = "green" if (mean is not None and mean >= dim_goal) else ("orange" if (mean is not None and dim_goal - mean <= 0.5) else "red")
                        
                        bar_html = f"""
                        <div class='progress-bar'>
                            <div class='progress-fill {progress_class}' style='width:{int(pct*100)}%;'></div>
                        </div>
                        """
                        st.markdown(
                            f"<div class='item-row'><span class='item-name'>{it}</span><span class='item-mean'>{(mean if mean is not None else 0):.2f}</span></div>"
                            + bar_html,
                            unsafe_allow_html=True,
                        )
                        # micro-sugest√µes
                        gap = None
                        try:
                            gap = (dim_goal - float(mean)) if (mean is not None) else None
                        except Exception:
                            gap = None
                        suggs = []
                        low_gap = (gap is not None and gap >= 0.2)
                        it_lower = it.lower()
                        if "tempo" in it_lower or "agilidade" in it_lower:
                            suggs.append("Ajustar SLAs ou prioriza√ß√£o de atendimentos")
                        if "instru" in it_lower or "guia" in it_lower or "manual" in it_lower:
                            suggs.append("Melhorar instru√ß√µes de uso com exemplos passo a passo")
                        if "sistema" in it_lower or "plataforma" in it_lower or "portal" in it_lower:
                            suggs.append("Revisar UX e reduzir cliques para concluir tarefas")
                        if "chatbot" in it_lower or "ia" in it_lower:
                            suggs.append("Aprimorar respostas do chatbot com base em d√∫vidas frequentes")
                        if not suggs:
                            suggs = [
                                "Treinamento r√°pido para equipe e usu√°rios",
                                "Padronizar mensagens e fluxos",
                                "Revisar gargalos e otimizar etapas cr√≠ticas",
                            ]
                        if low_gap:
                            st.markdown("<div class='sugg'>" + "<br>".join([f"‚Ä¢ {s}" for s in suggs[:2]]) + "</div>", unsafe_allow_html=True)
                        # micro-sugest√µes por item
                        try:
                            goal_dim = float((prefs or {}).get("goal_by_dimension", {}).get(dim_name, goal)) if isinstance(prefs, dict) else float(goal)
                        except Exception:
                            goal_dim = float(goal)
                        sugs = []
                        it_lower = it.lower()
                        if any(k in it_lower for k in ["tempo", "agilidade", "prazo", "resposta"]):
                            sugs.extend(["Ajustar tempos de resposta", "Automatizar etapas cr√≠ticas"])
                        if any(k in it_lower for k in ["instru", "guia", "manual", "orienta", "informac"]):
                            sugs.extend(["Melhorar instru√ß√µes e material de apoio", "Revisar textos da interface"])
                        if any(k in it_lower for k in ["sistema", "servi", "acesso", "localizar", "encontrar", "navega"]):
                            sugs.extend(["Revisar arquitetura de informa√ß√£o", "Treinamento de uso do sistema"])
                        if any(k in it_lower for k in ["real", "chatbot", "ia", "intera", "atendimento"]):
                            sugs.extend(["Expandir canais em tempo real", "Treinar chatbot"])
                        # base gap
                        try:
                            gap = max(0.0, float(goal_dim) - float(mean))
                        except Exception:
                            gap = 0.0
                        if gap >= 1.0:
                            sugs.insert(0, "Plano de a√ß√£o com respons√°veis e prazos")
                            sugs.append("Treinamento com simula√ß√µes pr√°ticas")
                        elif gap > 0:
                            sugs.append("Ajustes de processo e comunica√ß√£o")
                        if not sugs:
                            sugs = ["Entrevistar usu√°rios", "Definir melhoria incremental e medir impacto"]
                        for s in sugs[:3]:
                            st.markdown(f"<div class='sugg'><i>üí° {s}</i></div>", unsafe_allow_html=True)
                    st.markdown("</div>", unsafe_allow_html=True)
        
        # --- Aba: Lista completa (mant√©m agrupamento em 3 colunas com filtro) ---
        with tab_list:
            insight_options = {"Cr√≠ticos": "criticos", "Abaixo da meta": "acoes", "Bons (‚â• meta)": "bons"}
            sel = st.multiselect("Filtrar tipos de insight", list(insight_options.keys()), default=list(insight_options.keys()))
            only_pri = st.checkbox("Mostrar apenas cr√≠ticos", value=False, key="only_pri_list")
            if only_pri:
                sel = ["Cr√≠ticos"]
            selected_keys = [insight_options[k] for k in sel]
        
            c1, c2, c3 = st.columns(3)
        
            def render_list(container, items, title, color):
                container.markdown(f"**{title}**")
                if not items:
                    container.write("‚Äî")
                    return
                for item, dim, mean in items:
                    container.write(f"- **[{dim}]** {item} ‚Üí m√©dia **{mean:.2f}**")
        
            if "criticos" in selected_keys:
                render_list(c1, pri, "üî¥ Cr√≠ticos (muito abaixo da meta)", "red")
            else:
                c1.write("‚Äî")
            if "acoes" in selected_keys:
                render_list(c2, aco, "üü† A√ß√µes necess√°rias (abaixo da meta)", "orange")
            else:
                c2.write("‚Äî")
            if "bons" in selected_keys:
                render_list(c3, bons, "üü¢ Itens com bom desempenho (‚â• meta)", "green")
            else:
                c3.write("‚Äî")
        
        # --- Aba: A√ß√µes coordenadas (correla√ß√£o por dimens√£o) ---
        with tab_corr:
            st.caption("Sugest√µes de sequ√™ncias de a√ß√£o com base em correla√ß√µes entre itens de uma mesma dimens√£o.")
            with st.expander("Ver correla√ß√µes e sequ√™ncias sugeridas", expanded=False):
                threshold = st.slider("Correla√ß√£o m√≠nima (œÅ)", 0.3, 0.9, 0.5, 0.05, key="corr_thr_tabs")
                max_pairs = st.number_input("M√°ximo de pares por dimens√£o", min_value=1, max_value=10, value=3, step=1, key="corr_max_pairs_tabs")
                for dim_name, its in DIMENSIONS.items():
                    available = [it for it in its if it in df_f.columns]
                    if len(available) < 2:
                        continue
                    num_df = pd.DataFrame({it: normalize_likert(df_f[it]) for it in available})
                    if num_df.dropna(how="all").shape[1] < 2:
                        continue
                    corr = num_df.corr(method="spearman")
                    pairs = []
                    for i, it1 in enumerate(available):
                        for it2 in available[i+1:]:
                            try:
                                rho = float(corr.loc[it1, it2])
                            except Exception:
                                rho = np.nan
                            if pd.notna(rho) and rho >= threshold:
                                m1 = metrics["items"][it1]["mean"]
                                m2 = metrics["items"][it2]["mean"]
                                shortfall = max(0.0, float(goal) - float(m1)) + max(0.0, float(goal) - float(m2))
                                pairs.append((it1, it2, rho, shortfall))
                        if not pairs:
                            continue
                        pairs.sort(key=lambda x: (-x[3], -x[2]))
                        st.markdown(f"**{dim_name}**")
                        for it1, it2, rho, shortfall in pairs[:int(max_pairs)]:
                            st.write(f"- {it1} ‚Üî {it2} (œÅ‚âà{rho:.2f}). Sequ√™ncia sugerida: atuar em {it1} e, em seguida, refor√ßar {it2}. D√©ficit conjunto: {shortfall:.2f}.")
        # ===== Fim do novo layout =====
        # Bloco de frequ√™ncias por item removido (poder√° voltar futuramente, agora substitu√≠do pela An√°lise Detalhada).

# -----------------------------
# Page: An√°lise Detalhada
# -----------------------------
if page == "An√°lise Detalhada":
    st.header("üî¨ An√°lise Estat√≠stica Detalhada")
    
    if st.session_state.data is None:
        st.info("Carregue dados na p√°gina **Upload de Arquivo** primeiro.")
    else:
        df = st.session_state.data.copy()
        # Aplicar filtro de conjunto de quest√µes
        df = filter_by_question_set(df, st.session_state.question_set)
        df_f = filters_ui(df)
        
        # Ensure global variables are updated for current question set
        update_global_variables(st.session_state.question_set)
        
        # Prepare data for analysis
        df_analysis = prepare_data_for_analysis(df_f)
        
        st.info(f"üìä **Analisando:** {len(df_analysis)} respostas v√°lidas | Dimens√µes: {list(DIMENSIONS.keys())}")
        
        # Tabs for different analyses
        tab1, tab2 = st.tabs([ 
            "üéØ Regress√µes vs Satisfa√ß√£o", 
            "üìä Correla√ß√µes e Associa√ß√µes"
        ])
        
        # Tab 1: Regressions by Dimension
        # Tab 1: Satisfaction Regression
        with tab1:
            st.subheader("Regress√µes das Dimens√µes vs Satisfa√ß√£o Geral")
            st.caption("An√°lise de como cada dimens√£o influencia a satisfa√ß√£o geral")
            
            if SAT_FIELD in df_analysis.columns:
                if st.button("üéØ Executar An√°lise de Satisfa√ß√£o", key="run_satisfaction"):
                    st.success("‚úÖ An√°lise de satisfa√ß√£o executada")
                    
                    # Prepare data - only use score columns that exist in the DataFrame
                    available_score_cols = [f'{dim}_score' for dim in DIMENSIONS.keys() if f'{dim}_score' in df_analysis.columns]
                    if not available_score_cols:
                        st.warning("Nenhuma coluna de score encontrada. Verifique se os dados foram processados corretamente.")
                        st.stop()
                    
                    satisfaction_data = df_analysis[[SAT_FIELD] + available_score_cols].dropna()
                    
                    if len(satisfaction_data) > 10:
                        # Multiple regression
                        X = satisfaction_data[available_score_cols]
                        y = satisfaction_data[SAT_FIELD]
                        
                        X_with_const = sm.add_constant(X)
                        model = sm.OLS(y, X_with_const).fit()
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown("#### üìä Modelo de Satisfa√ß√£o")
                            st.write(f"**R¬≤ Ajustado:** {model.rsquared_adj:.3f}")
                            st.write(f"**F-stat√≠stico:** {model.fvalue:.2f}")
                            st.write(f"**p-valor (F):** {model.f_pvalue:.4f}")
                            st.write(f"**Observa√ß√µes:** {int(model.nobs)}")
                        
                        with col2:
                            st.markdown("#### üìà Influ√™ncia das Dimens√µes")
                            coef_df = pd.DataFrame({
                                'Dimens√£o': ['Intercepto'] + list(DIMENSIONS.keys()),
                                'Coeficiente': model.params.values,
                                'p-valor': model.pvalues.values
                            })
                            
                            # Sort by coefficient (excluding intercept)
                            coef_df_sorted = coef_df.iloc[1:].sort_values('Coeficiente', ascending=False)
                            
                            for _, row in coef_df_sorted.iterrows():
                                significance = "‚úÖ" if row['p-valor'] < 0.05 else "‚ùå"
                                st.write(f"{significance} **{row['Dimens√£o']}**: Œ≤ = {row['Coeficiente']:.3f}")
                        
                        # Visualization
                        fig = px.bar(
                            coef_df_sorted, 
                            x='Coeficiente', 
                            y='Dimens√£o',
                            title="Influ√™ncia das Dimens√µes na Satisfa√ß√£o Geral",
                            color='p-valor',
                            color_continuous_scale='RdYlGn_r'
                        )
                        fig.update_layout(height=400)
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Interpretation
                        st.markdown("#### üí° Interpreta√ß√£o")
                        most_important = coef_df_sorted.iloc[0]
                        least_important = coef_df_sorted.iloc[-1]
                        
                        st.write(f"**Dimens√£o mais importante:** {most_important['Dimens√£o']} (Œ≤ = {most_important['Coeficiente']:.3f})")
                        st.write(f"**Dimens√£o menos importante:** {least_important['Dimens√£o']} (Œ≤ = {least_important['Coeficiente']:.3f})")
                    
                    else:
                        st.error("‚ùå Dados insuficientes para an√°lise de satisfa√ß√£o.")
            else:
                st.warning("‚ö†Ô∏è Campo de satisfa√ß√£o n√£o encontrado nos dados.")
        
        # Tab 2: Correlations and Associations
        with tab2:
            st.subheader("Correla√ß√µes e Associa√ß√µes")
            st.caption("An√°lise de correla√ß√µes entre vari√°veis e testes de associa√ß√£o")
            
            if st.button("üìä Executar An√°lise de Correla√ß√µes", key="run_correlations"):
                st.success("‚úÖ An√°lise de correla√ß√µes executada")
                
                # Prepare correlation data - only use score columns that exist
                available_score_cols = [f'{dim}_score' for dim in DIMENSIONS.keys() if f'{dim}_score' in df_analysis.columns]
                if not available_score_cols:
                    st.warning("Nenhuma coluna de score encontrada para an√°lise de correla√ß√µes.")
                    st.stop()
                
                corr_data = df_analysis[available_score_cols].dropna()
                
                if len(corr_data) > 10:
                    # Correlation matrix
                    correlation_matrix = corr_data.corr()
                    
                    # Heatmap
                    fig = px.imshow(
                        correlation_matrix,
                        text_auto=True,
                        aspect="auto",
                        title="Matriz de Correla√ß√£o entre Dimens√µes",
                        color_continuous_scale='RdBu_r'
                    )
                    fig.update_layout(height=400)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Detailed correlations
                    st.markdown("#### üìà Correla√ß√µes Detalhadas")
                    
                    correlations = []
                    for i, dim1 in enumerate(DIMENSIONS.keys()):
                        for j, dim2 in enumerate(DIMENSIONS.keys()):
                            if i < j:  # Avoid duplicates
                                corr_val = correlation_matrix.loc[f'{dim1}_score', f'{dim2}_score']
                                correlations.append({
                                    'Dimens√£o 1': dim1,
                                    'Dimens√£o 2': dim2,
                                    'Correla√ß√£o': corr_val,
                                    'Intensidade': 'Forte' if abs(corr_val) > 0.7 else 'Moderada' if abs(corr_val) > 0.3 else 'Fraca'
                                })
                    
                    corr_df = pd.DataFrame(correlations)
                    corr_df = corr_df.sort_values('Correla√ß√£o', key=abs, ascending=False)
                    
                    st.dataframe(corr_df.style.format({'Correla√ß√£o': '{:.3f}'}), use_container_width=True)
                    
                    # Categorical associations
                    st.markdown("#### üîó Associa√ß√µes com Vari√°veis Categ√≥ricas")
                    
                    # Sex vs Dimensions
                    if PROFILE_FIELDS["Sexo"] in df_analysis.columns:
                        st.markdown("##### Associa√ß√£o: Sexo vs Dimens√µes")
                        
                        available_score_cols = [f'{dim}_score' for dim in DIMENSIONS.keys() if f'{dim}_score' in df_analysis.columns]
                        if not available_score_cols:
                            st.warning("Nenhuma coluna de score encontrada para an√°lise por sexo.")
                        else:
                            sex_dim_data = df_analysis[[PROFILE_FIELDS["Sexo"]] + available_score_cols].dropna()
                            
                            if len(sex_dim_data) > 10:
                                # ANOVA for each dimension
                                for dim in available_score_cols:
                                    dim_name = dim.replace('_score', '')
                                    groups = [group[dim].dropna() for name, group in sex_dim_data.groupby(PROFILE_FIELDS["Sexo"])]
                                    if len(groups) > 1 and all(len(g) > 0 for g in groups):
                                        f_stat, p_val = stats.f_oneway(*groups)
                                        significance = "‚úÖ" if p_val < 0.05 else "‚ùå"
                                        st.write(f"{significance} **{dim_name}**: F = {f_stat:.3f}, p = {p_val:.4f}")
                    
                    # Servidor P√∫blico vs Dimensions
                    # Handle different field names for public servant field
                    servidor_field = PROFILE_FIELDS.get("Servidor P√∫blico") or PROFILE_FIELDS.get("Funcionario_Publico")
                    if servidor_field and servidor_field in df_analysis.columns:
                        st.markdown("##### Associa√ß√£o: Servidor P√∫blico vs Dimens√µes")
                        
                        available_score_cols = [f'{dim}_score' for dim in DIMENSIONS.keys() if f'{dim}_score' in df_analysis.columns]
                        if not available_score_cols:
                            st.warning("Nenhuma coluna de score encontrada para an√°lise de servidor p√∫blico.")
                        else:
                            serv_dim_data = df_analysis[[servidor_field] + available_score_cols].dropna()
                            
                            if len(serv_dim_data) > 10:
                                for dim in available_score_cols:
                                    dim_name = dim.replace('_score', '')
                                    groups = [group[dim].dropna() for name, group in serv_dim_data.groupby(servidor_field)]
                                    if len(groups) > 1 and all(len(g) > 0 for g in groups):
                                        f_stat, p_val = stats.f_oneway(*groups)
                                        significance = "‚úÖ" if p_val < 0.05 else "‚ùå"
                                        st.write(f"{significance} **{dim_name}**: F = {f_stat:.3f}, p = {p_val:.4f}")
                
                else:
                    st.error("‚ùå Dados insuficientes para an√°lise de correla√ß√µes.")

# -----------------------------
# Page: Perfil
# -----------------------------
if page == "Perfil":
    st.header("üë§ Perfil do Usu√°rio")
    if st.session_state.auth["logged_in"]:
        st.write(f"**E-mail:** {st.session_state.auth['email']}")
    else:
        st.info("Modo demo: sem autentica√ß√£o real.")

    st.subheader("Hist√≥rico de Uploads")
    if st.session_state.auth["logged_in"]:
        rec = st.session_state.dm.get_user_uploads(st.session_state.auth["email"])
        if rec:
            st.dataframe(pd.DataFrame([rec.model_dump()]))
        elif st.session_state.uploads:
            st.dataframe(pd.DataFrame(st.session_state.uploads))
        else:
            st.write("Nenhum upload registrado ainda.")
    else:
        st.write("Nenhum upload (modo demo).")

    st.subheader("An√°lise de Perfil")
    if "data" in st.session_state and st.session_state.data is not None:
        df = st.session_state.data.copy()
        # Aplicar filtro de conjunto de quest√µes
        df = filter_by_question_set(df, st.session_state.question_set)
        df_filtered = filters_ui(df)
        df_analysis = prepare_data_for_analysis(df_filtered)

        if df_analysis.empty:
            st.warning("Nenhum dado dispon√≠vel ap√≥s a aplica√ß√£o dos filtros.")
        else:
            st.info(f"üìä **Analisando:** {len(df_analysis)} respostas v√°lidas (ap√≥s filtros)")
            
            # Iterate over each profile question
            for profile_key, profile_question in PROFILE_FIELDS.items():
                if profile_question in df_analysis.columns:
                    st.markdown(f"---")
                    st.markdown(f"### {profile_question}")
                    
                    # --- M√©tricas de resumo ---
                    col1, col2, col3 = st.columns(3)
                    total_responses = df_analysis[profile_question].count()
                    unique_responses = df_analysis[profile_question].nunique()
                    
                    with col1:
                        st.metric("Total de Respostas", total_responses)
                    with col2:
                        st.metric("Op√ß√µes Distintas", unique_responses)
                    with col3:
                        # Frequency table
                        freq_table = df_analysis[profile_question].value_counts().reset_index()
                        freq_table.columns = ['Op√ß√£o', 'Contagem']
                        st.dataframe(freq_table, use_container_width=True, height=150)

                    # --- Histograma (largura total) ---
                    st.markdown("##### Distribui√ß√£o das Respostas")
                    try:
                        # Tratamento especial para idade - categoriza√ß√£o por quartis
                        if 'idade' in profile_question.lower() or 'age' in profile_question.lower():
                            # Criar categorias por quartis para idade
                            age_data = df_analysis[profile_question].dropna()
                            if len(age_data) > 0:
                                quartiles = age_data.quantile([0.25, 0.5, 0.75])
                                
                                def categorize_age(age):
                                    if pd.isna(age):
                                        return 'N√£o informado'
                                    elif age <= quartiles[0.25]:
                                        return f'Q1: ‚â§{quartiles[0.25]:.0f} anos'
                                    elif age <= quartiles[0.5]:
                                        return f'Q2: {quartiles[0.25]:.0f}-{quartiles[0.5]:.0f} anos'
                                    elif age <= quartiles[0.75]:
                                        return f'Q3: {quartiles[0.5]:.0f}-{quartiles[0.75]:.0f} anos'
                                    else:
                                        return f'Q4: >{quartiles[0.75]:.0f} anos'
                                
                                df_analysis_temp = df_analysis.copy()
                                df_analysis_temp[f'{profile_question}_quartil'] = df_analysis_temp[profile_question].apply(categorize_age)
                                
                                hist_fig = px.histogram(
                                    df_analysis_temp.dropna(subset=[f'{profile_question}_quartil']), 
                                    x=f'{profile_question}_quartil',
                                    title=f"Distribui√ß√£o por Quartis - '{profile_question}'",
                                    text_auto=True
                                )
                                hist_fig.update_layout(bargap=0.2, xaxis_title="Quartis de Idade")
                                st.plotly_chart(hist_fig, use_container_width=True)
                        else:
                            hist_fig = px.histogram(
                                df_analysis.dropna(subset=[profile_question]), 
                                x=profile_question,
                                title=f"Distribui√ß√£o de '{profile_question}'",
                                text_auto=True
                            )
                            hist_fig.update_layout(bargap=0.2)
                            st.plotly_chart(hist_fig, use_container_width=True)
                    except Exception as e:
                        st.warning(f"N√£o foi poss√≠vel gerar o histograma: {e}")

                    # --- Radar Chart (largura total) ---
                    st.markdown("##### An√°lise por Dimens√£o (Radar)")
                    
                    # Para idade, usar quartis; para outros, usar valores originais
                    if 'idade' in profile_question.lower() or 'age' in profile_question.lower():
                        age_data = df_analysis[profile_question].dropna()
                        if len(age_data) > 0:
                            quartiles = age_data.quantile([0.25, 0.5, 0.75])
                            
                            def categorize_age(age):
                                if pd.isna(age):
                                    return 'N√£o informado'
                                elif age <= quartiles[0.25]:
                                    return f'Q1: ‚â§{quartiles[0.25]:.0f} anos'
                                elif age <= quartiles[0.5]:
                                    return f'Q2: {quartiles[0.25]:.0f}-{quartiles[0.5]:.0f} anos'
                                elif age <= quartiles[0.75]:
                                    return f'Q3: {quartiles[0.5]:.0f}-{quartiles[0.75]:.0f} anos'
                                else:
                                    return f'Q4: >{quartiles[0.75]:.0f} anos'
                            
                            df_analysis_temp = df_analysis.copy()
                            df_analysis_temp[f'{profile_question}_quartil'] = df_analysis_temp[profile_question].apply(categorize_age)
                            options = df_analysis_temp[f'{profile_question}_quartil'].dropna().unique()
                            analysis_field = f'{profile_question}_quartil'
                            df_for_radar = df_analysis_temp
                        else:
                            options = []
                            analysis_field = profile_question
                            df_for_radar = df_analysis
                    else:
                        options = df_analysis[profile_question].dropna().unique()
                        analysis_field = profile_question
                        df_for_radar = df_analysis
                    
                    # Limitar para n√£o poluir o gr√°fico
                    if len(options) > 1 and len(options) < 8:
                        
                        radar_fig = go.Figure()
                        
                        dimension_score_fields = [f'{dim}_score' for dim in DIMENSIONS.keys() if f'{dim}_score' in df_for_radar.columns]
                        dimension_names = [dim for dim in DIMENSIONS.keys() if f'{dim}_score' in df_for_radar.columns]

                        if dimension_score_fields:
                            for option in sorted(options):
                                df_option = df_for_radar[df_for_radar[analysis_field] == option]
                                
                                # Calculate mean for each dimension score for this group
                                # Keep Likert scale (1-5)
                                mean_scores_likert = df_option[dimension_score_fields].mean().values
                                mean_scores = [score if not np.isnan(score) else 1 for score in mean_scores_likert]
                                
                                radar_fig.add_trace(go.Scatterpolar(
                                    r=mean_scores,
                                    theta=dimension_names,
                                    fill='toself',
                                    name=str(option)
                                ))
                            
                            radar_fig.update_layout(
                                polar=dict(
                                    radialaxis=dict(
                                        visible=True,
                                        range=[1, 5], # Escala de 1 a 5
                                        tickvals=[1, 2, 3, 4, 5],
                                        ticktext=['1', '2', '3', '4', '5']
                                    )
                                ),
                                showlegend=True,
                                title=f"Radar de Escala 1-5 - '{profile_question}'"
                            )
                            st.plotly_chart(radar_fig, use_container_width=True)
                        else:
                            st.warning(f"As pontua√ß√µes das dimens√µes n√£o foram calculadas. Imposs√≠vel gerar o gr√°fico de radar.")

                    elif len(options) >= 8:
                        st.info(f"Muitas op√ß√µes ({len(options)}) para exibir o gr√°fico de radar. O gr√°fico foi omitido para maior clareza.")
                    else:
                        st.info("N√£o h√° op√ß√µes suficientes para uma compara√ß√£o no gr√°fico de radar.")

    else:
        st.info("Fa√ßa o upload de um arquivo para ver a an√°lise de perfil.")


# -----------------------------
# Page: Portal Transpar√™ncia
# -----------------------------
if page == "Portal Transpar√™ncia":
    st.header("üèõÔ∏è Portal Transpar√™ncia - Dashboard de Qualidade")
    
    # Carregar dados espec√≠ficos para Portal Transpar√™ncia
    if st.session_state.question_set == "8 quest√µes":
        if hasattr(st.session_state, 'uploaded_8q') and st.session_state.uploaded_8q is not None:
            try:
                df_transp = read_csv(st.session_state.uploaded_8q)
                data_source_name = st.session_state.uploaded_8q.name
            except Exception as e:
                st.error(f"Erro ao carregar arquivo: {e}")
                df_transp = None
        else:
            try:
                # Usar v√≠rgula como separador para o arquivo basetransp.csv
                df_transp = pd.read_csv(os.path.join("sample_data", "basetransp.csv"), sep=",", encoding="utf-8")
                data_source_name = "basetransp.csv (padr√£o)"
            except Exception as e:
                st.error(f"Erro ao carregar basetransp.csv: {e}")
                df_transp = None
    else:
        df_transp = st.session_state.data
        data_source_name = st.session_state.data_source
    
    if df_transp is None:
        st.warning("‚ö†Ô∏è Nenhum dado dispon√≠vel. Configure o conjunto de quest√µes para '8 quest√µes' ou fa√ßa upload de um arquivo.")
    else:
        st.info(f"üìä **Analisando dados de:** {data_source_name}")
        
        # Processar dados: remover linhas em branco e agrupar
        df_transp = df_transp.dropna(how='all')  # Remove linhas completamente vazias
        df_transp = df_transp.reset_index(drop=True)  # Reindexar ap√≥s remo√ß√£o
        
        # Definir as 8 quest√µes espec√≠ficas do Portal Transpar√™ncia
        # Usar os textos reais das colunas do CSV
        questoes_portal = {
            "O Portal √© f√°cil de usar.": "O Portal √© f√°cil de usar",
            "√â f√°cil localizar os dados e as informa√ß√µes no Portal.": "√â f√°cil localizar os dados e as informa√ß√µes no Portal", 
            "A navega√ß√£o pelo Portal √© intuitiva.": "A navega√ß√£o pelo Portal √© intuitiva",
            "O Portal funciona sem falhas.": "O Portal funciona sem falhas",
            "As informa√ß√µes s√£o f√°ceis de entender.": "As informa√ß√µes s√£o f√°ceis de entender",
            "As informa√ß√µes s√£o precisas.": "As informa√ß√µes s√£o precisas",
            "As informa√ß√µes disponibilizadas est√£o atualizadas.": "As informa√ß√µes disponibilizadas est√£o atualizadas",
            "Consigo obter o que preciso no menor tempo poss√≠vel.": "Consigo obter o que preciso no menor tempo poss√≠vel",
            "Qual o seu n√≠vel de satisfa√ß√£o com o Portal da Transpar√™ncia do RS?": "N√≠vel de satisfa√ß√£o com o Portal da Transpar√™ncia do RS"
        }
        
        # Mapeamento da escala Likert (1-5)
        likert_mapping = {
            "Discordo totalmente": 1,
            "Discordo": 2, 
            "Neutro": 3,
            "Concordo": 4,
            "Concordo totalmente": 5,
            # Para satisfa√ß√£o
            "Muito insatisfeito": 1,
            "Insatisfeito": 2,
            "Neutro": 3,
            "Satisfeito": 4,
            "Muito satisfeito": 5
        }
        
        # Aplicar mapeamento num√©rico
        for col in df_transp.columns:
            if col in questoes_portal.keys():
                df_transp[col] = df_transp[col].map(likert_mapping).fillna(df_transp[col])
        
        # Aplicar filtros
        df_filtered = filters_ui(df_transp)
        
        # Calcular m√©dias para cada quest√£o
        medias_questoes = {}
        for questao_col, questao_desc in questoes_portal.items():
            if questao_col in df_filtered.columns:
                media = df_filtered[questao_col].mean()
                medias_questoes[questao_desc] = media if not pd.isna(media) else 0
        
        # Header com m√©tricas principais
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üìä Total de Respostas", len(df_filtered))
        with col2:
            st.metric("üéØ Meta Estabelecida", f"{goal:.1f}")
        with col3:
            if "N√≠vel de satisfa√ß√£o com o Portal da Transpar√™ncia do RS" in medias_questoes:
                satisfacao_media = medias_questoes["N√≠vel de satisfa√ß√£o com o Portal da Transpar√™ncia do RS"]
                st.metric("üòä Satisfa√ß√£o M√©dia", f"{satisfacao_media:.2f}")
            else:
                st.metric("üìã Quest√µes Analisadas", "8")
        with col4:
            abaixo_meta = sum(1 for media in medias_questoes.values() if media < goal)
            st.metric("‚ö†Ô∏è Abaixo da Meta", f"{abaixo_meta}/{len(medias_questoes)}")
        
        st.markdown("---")
        
        # Dashboard principal com duas colunas
        col_left, col_right = st.columns([2, 1])
        
        with col_left:
            st.subheader("üìà Vis√£o Geral das 8 Quest√µes")
            
            # Gr√°fico de radar
            if medias_questoes:
                questoes_sistema = [q for q in medias_questoes.keys() if "satisfa√ß√£o" not in q.lower()]
                r_vals = [medias_questoes[q] for q in questoes_sistema]
                
                if questoes_sistema and r_vals:
                    fig_radar = go.Figure()
                    fig_radar.add_trace(go.Scatterpolar(
                        r=r_vals, 
                        theta=questoes_sistema, 
                        fill="toself", 
                        name="M√©dia Atual",
                        line_color='#1f77b4'
                    ))
                    
                    # Adicionar linha da meta
                    meta_vals = [goal] * len(questoes_sistema)
                    fig_radar.add_trace(go.Scatterpolar(
                        r=meta_vals, 
                        theta=questoes_sistema, 
                        fill=None, 
                        name="Meta",
                        line=dict(color='red', dash='dash', width=2)
                    ))
                    
                    fig_radar.update_layout(
                        polar=dict(radialaxis=dict(
                            visible=True, 
                            range=[1, 5],
                            tickvals=[1, 2, 3, 4, 5],
                            ticktext=['1', '2', '3', '4', '5']
                        )),
                        showlegend=True,
                        height=500,
                        title="Compara√ß√£o: Desempenho Atual vs Meta"
                    )
                    st.plotly_chart(fig_radar, use_container_width=True)
                else:
                    st.warning("‚ö†Ô∏è N√£o h√° quest√µes v√°lidas para exibir no gr√°fico de radar.")
            else:
                st.warning("‚ö†Ô∏è N√£o h√° dados suficientes para exibir o gr√°fico de radar. Verifique se o arquivo cont√©m as quest√µes esperadas.")
            
            # Gr√°fico de barras horizontal
            st.subheader("üìä Ranking das Quest√µes")
            
            dim_data = []
            for questao, media in medias_questoes.items():
                if "satisfa√ß√£o" not in questao.lower():  # Excluir satisfa√ß√£o do ranking
                    dim_data.append({
                        'Quest√£o': questao[:30] + "..." if len(questao) > 30 else questao,
                        'M√©dia': media,
                        'Status': 'Acima da Meta' if media >= goal else 'Abaixo da Meta'
                    })
            
            if dim_data:  # Verificar se h√° dados antes de criar o DataFrame
                try:
                    df_dim = pd.DataFrame(dim_data)
                    # Verificar se o DataFrame tem dados e a coluna 'M√©dia' existe
                    if not df_dim.empty and 'M√©dia' in df_dim.columns:
                        df_dim = df_dim.sort_values('M√©dia', ascending=True)
                        
                        # Criar o gr√°fico apenas se temos dados v√°lidos
                        fig_bar = px.bar(
                            df_dim, 
                            x='M√©dia', 
                            y='Quest√£o', 
                            color='Status',
                            color_discrete_map={
                                'Acima da Meta': '#2ecc71',
                                'Abaixo da Meta': '#e74c3c'
                            },
                            orientation='h',
                            title="Desempenho por Quest√£o"
                        )
                        fig_bar.add_vline(x=goal, line_dash="dash", line_color="red", 
                                         annotation_text=f"Meta: {goal}")
                        fig_bar.update_layout(height=400)
                        st.plotly_chart(fig_bar, use_container_width=True)
                    else:
                        st.warning("‚ö†Ô∏è DataFrame criado mas sem dados v√°lidos para o gr√°fico.")
                except Exception as e:
                    st.error(f"Erro ao criar DataFrame: {e}")
            else:
                st.warning("‚ö†Ô∏è N√£o h√° dados suficientes para gerar o gr√°fico de barras. Verifique se os dados foram carregados corretamente.")
        
        with col_right:
            st.subheader("üéØ Status das Quest√µes")
            
            # Cards de status
            for questao, media in medias_questoes.items():
                if "satisfa√ß√£o" not in questao.lower():  # Excluir satisfa√ß√£o dos cards
                    if media >= goal:
                        status_color = "#d4edda"
                        status_icon = "‚úÖ"
                        status_text = "Meta Atingida"
                    else:
                        status_color = "#f8d7da"
                        status_icon = "‚ö†Ô∏è"
                        status_text = "Abaixo da Meta"
                    
                    questao_short = questao[:25] + "..." if len(questao) > 25 else questao
                    st.markdown(f"""
                    <div style="
                        background-color: {status_color}; 
                        padding: 10px; 
                        border-radius: 5px; 
                        margin-bottom: 10px;
                        border-left: 4px solid {'#28a745' if media >= goal else '#dc3545'};
                    ">
                        <strong>{status_icon} {questao_short}</strong><br>
                        M√©dia: <strong>{media:.2f}</strong><br>
                        <small>{status_text}</small>
                    </div>
                    """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        # Se√ß√£o de A√ß√µes Sugeridas
        st.subheader("üí° A√ß√µes Sugeridas para Melhoria")
        st.write("Com base na an√°lise das m√©dias, aqui est√£o as a√ß√µes recomendadas para cada quest√£o:")
        
        # Definir a√ß√µes por quest√£o (baseado no acoesDash.docx.md)
        acoes_por_questao = {
            "O Portal √© f√°cil de usar": {
                "titulo": "üé® Melhorar Usabilidade",
                "acoes": [
                    "Implementar busca inteligente com filtros avan√ßados e sugest√µes autom√°ticas",
                    "Realizar testes de usabilidade com usu√°rios reais para identificar pontos de fric√ß√£o",
                    "Otimizar interface para dispositivos m√≥veis com design responsivo",
                    "Adicionar tutoriais interativos e onboarding para novos usu√°rios",
                    "Criar atalhos de teclado para usu√°rios avan√ßados"
                ]
            },
            "√â f√°cil localizar os dados e as informa√ß√µes no Portal": {
                "titulo": "üîç Facilitar Localiza√ß√£o de Dados",
                "acoes": [
                    "Reorganizar categoriza√ß√£o de dados por frequ√™ncia de uso e relev√¢ncia",
                    "Implementar sistema de tags e metadados para melhor organiza√ß√£o",
                    "Criar mapa visual do portal com localiza√ß√£o de informa√ß√µes",
                    "Desenvolver busca sem√¢ntica que entenda sin√¥nimos e contexto",
                    "Adicionar filtros inteligentes baseados no perfil do usu√°rio"
                ]
            },
            "A navega√ß√£o pelo Portal √© intuitiva": {
                "titulo": "üß≠ Aprimorar Navega√ß√£o",
                "acoes": [
                    "Implementar breadcrumbs em todas as p√°ginas para orienta√ß√£o",
                    "Criar menu de navega√ß√£o contextual baseado na se√ß√£o atual",
                    "Desenvolver sistema de navega√ß√£o por abas para m√∫ltiplas consultas",
                    "Adicionar hist√≥rico de navega√ß√£o e p√°ginas visitadas recentemente",
                    "Implementar navega√ß√£o por gestos em dispositivos touch"
                ]
            },
            "O Portal funciona sem falhas": {
                "titulo": "‚öôÔ∏è Otimizar Funcionamento",
                "acoes": [
                    "Implementar monitoramento de performance em tempo real com alertas",
                    "Criar dashboard de status do sistema vis√≠vel aos usu√°rios",
                    "Estabelecer SLA de 99.9% de disponibilidade com compensa√ß√µes",
                    "Implementar sistema de cache inteligente para reduzir lat√™ncia",
                    "Desenvolver testes automatizados de regress√£o e performance"
                ]
            },
            "As informa√ß√µes s√£o f√°ceis de entender": {
                "titulo": "üí° Aumentar Clareza",
                "acoes": [
                    "Desenvolver gloss√°rio interativo de termos t√©cnicos e jur√≠dicos",
                    "Padronizar linguagem simples e acess√≠vel em todo o portal",
                    "Criar guias visuais e infogr√°ficos para processos complexos",
                    "Implementar sistema de ajuda contextual com tooltips explicativos",
                    "Adicionar exemplos pr√°ticos para cada tipo de informa√ß√£o"
                ]
            },
            "As informa√ß√µes s√£o precisas": {
                "titulo": "üéØ Melhorar Precis√£o",
                "acoes": [
                    "Implementar concilia√ß√£o autom√°tica de dados entre sistemas",
                    "Criar valida√ß√µes em tempo real com regras de neg√≥cio",
                    "Estabelecer processo de auditoria cont√≠nua de qualidade dos dados",
                    "Desenvolver alertas autom√°ticos para inconsist√™ncias detectadas",
                    "Implementar versionamento e rastreabilidade de altera√ß√µes"
                ]
            },
            "As informa√ß√µes disponibilizadas est√£o atualizadas": {
                "titulo": "üîÑ Automatizar Atualiza√ß√£o",
                "acoes": [
                    "Implementar atualiza√ß√£o autom√°tica de dados via APIs integradas",
                    "Criar cronograma transparente de publica√ß√£o com datas previstas",
                    "Desenvolver notifica√ß√µes push para usu√°rios sobre novas atualiza√ß√µes",
                    "Estabelecer versionamento autom√°tico com hist√≥rico de mudan√ßas",
                    "Implementar indicadores visuais de √∫ltima atualiza√ß√£o em cada dataset"
                ]
            },
            "Consigo obter o que preciso no menor tempo poss√≠vel": {
                "titulo": "‚è±Ô∏è Reduzir Tempo de Acesso",
                "acoes": [
                    "Criar dashboard personalizado de acesso r√°pido por perfil de usu√°rio",
                    "Implementar busca por voz para consultas mais naturais",
                    "Otimizar consultas de banco de dados com indexa√ß√£o inteligente",
                    "Desenvolver API REST p√∫blica para integra√ß√£o com sistemas externos",
                    "Criar widgets embarc√°veis para sites de terceiros"
                ]
            }
        }
        
        # Mostrar a√ß√µes organizadas por prioridade
        questoes_abaixo_meta = [(q, m) for q, m in medias_questoes.items() if "satisfa√ß√£o" not in q.lower() and m < goal]
        questoes_acima_meta = [(q, m) for q, m in medias_questoes.items() if "satisfa√ß√£o" not in q.lower() and m >= goal]
        
        if questoes_abaixo_meta:
            st.markdown("### üö® Prioridade Alta - Quest√µes Abaixo da Meta")
            questoes_abaixo_meta.sort(key=lambda x: x[1])  # Ordenar por m√©dia (pior primeiro)
            
            for questao, media_atual in questoes_abaixo_meta:
                if questao in acoes_por_questao:
                    acao_info = acoes_por_questao[questao]
                    gap = goal - media_atual
                    
                    with st.expander(f"{acao_info['titulo']} - M√©dia: {media_atual:.2f} (Gap: -{gap:.2f})"):
                        st.write("**A√ß√µes Recomendadas:**")
                        for i, acao in enumerate(acao_info["acoes"], 1):
                            st.write(f"{i}. {acao}")
                        
                        # Barra de progresso
                        progresso = (media_atual / goal) * 100
                        st.progress(min(progresso / 100, 1.0))
                        st.caption(f"Progresso em rela√ß√£o √† meta: {progresso:.1f}%")
                        
                        # Indicador de prioridade
                        if media_atual < 2.5:
                            st.error("üî¥ **Prioridade Cr√≠tica** - Requer a√ß√£o imediata")
                        elif media_atual < 3.5:
                            st.warning("üü° **Prioridade Alta** - A√ß√£o necess√°ria em breve")
                        else:
                            st.info("üîµ **Prioridade M√©dia** - Melhorias incrementais")
        
        if questoes_acima_meta:
            st.markdown("### ‚úÖ Manuten√ß√£o - Quest√µes Acima da Meta")
            questoes_acima_meta.sort(key=lambda x: x[1], reverse=True)  # Ordenar por m√©dia (melhor primeiro)
            
            for questao, media_atual in questoes_acima_meta:
                if questao in acoes_por_questao:
                    acao_info = acoes_por_questao[questao]
                    
                    with st.expander(f"{acao_info['titulo']} - M√©dia: {media_atual:.2f} ‚úÖ"):
                        st.success("Esta quest√£o est√° atingindo a meta! A√ß√µes para manter e aprimorar:")
                        for i, acao in enumerate(acao_info["acoes"], 1):
                            st.write(f"{i}. {acao}")
                        
                        # Indicador de excel√™ncia
                        if media_atual >= 4.5:
                            st.success("üåü **Excel√™ncia** - Refer√™ncia para outras quest√µes")
                        else:
                            st.info("üìà **Bom desempenho** - Oportunidade de otimiza√ß√£o")
        
        # Resumo executivo
        st.markdown("---")
        st.subheader("üìã Resumo Executivo")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**üéØ Metas Atingidas:**")
            if questoes_acima_meta:
                for questao, media in questoes_acima_meta:
                    questao_short = questao[:40] + "..." if len(questao) > 40 else questao
                    st.write(f"‚úÖ {questao_short}: {media:.2f}")
            else:
                st.write("Nenhuma quest√£o atingiu a meta ainda.")
        
        with col2:
            st.markdown("**‚ö†Ô∏è Necessitam Aten√ß√£o:**")
            if questoes_abaixo_meta:
                for questao, media in questoes_abaixo_meta:
                    questao_short = questao[:40] + "..." if len(questao) > 40 else questao
                    gap = goal - media
                    st.write(f"üî¥ {questao_short}: {media:.2f} (Gap: -{gap:.2f})")
            else:
                st.write("Todas as quest√µes est√£o atingindo a meta! üéâ")
        
        # An√°lise de satisfa√ß√£o geral
        if "N√≠vel de satisfa√ß√£o com o Portal da Transpar√™ncia do RS" in medias_questoes:
            satisfacao_geral = medias_questoes["N√≠vel de satisfa√ß√£o com o Portal da Transpar√™ncia do RS"]
            st.markdown("---")
            st.subheader("üòä An√°lise de Satisfa√ß√£o Geral")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Satisfa√ß√£o Atual", f"{satisfacao_geral:.2f}")
            with col2:
                if satisfacao_geral >= goal:
                    st.success("Meta de Satisfa√ß√£o Atingida! ‚úÖ")
                else:
                    gap_sat = goal - satisfacao_geral
                    st.error(f"Gap de Satisfa√ß√£o: -{gap_sat:.2f}")
            with col3:
                # Correla√ß√£o com quest√µes t√©cnicas
                media_tecnica = np.mean([m for q, m in medias_questoes.items() if "satisfa√ß√£o" not in q.lower()])
                correlacao = abs(satisfacao_geral - media_tecnica)
                if correlacao < 0.5:
                    st.info("Alta correla√ß√£o com quest√µes t√©cnicas")
                else:
                    st.warning("Baixa correla√ß√£o - investigar fatores externos")
        
        # Indicadores de tend√™ncia e recomenda√ß√µes finais
        st.markdown("---")
        st.info("üí° **Dica:** Use os filtros na barra lateral para analisar segmentos espec√≠ficos da popula√ß√£o e identificar oportunidades de melhoria direcionadas.")
        
        # Exportar dados para an√°lise
        if st.button("üìä Exportar Relat√≥rio de An√°lise"):
            if not medias_questoes:
                st.warning("‚ö†Ô∏è N√£o h√° dados suficientes para gerar o relat√≥rio. Verifique os filtros aplicados.")
            else:
                relatorio_data = {
                    'Quest√£o': [],
                    'M√©dia': [],
                    'Status': [],
                    'Gap': [],
                    'Prioridade': []
                }
                
                for questao, media in medias_questoes.items():
                    if "satisfa√ß√£o" not in questao.lower():
                        relatorio_data['Quest√£o'].append(questao)
                        relatorio_data['M√©dia'].append(media)
                        relatorio_data['Status'].append('Acima da Meta' if media >= goal else 'Abaixo da Meta')
                        relatorio_data['Gap'].append(goal - media if media < goal else 0)
                        
                        if media < 2.5:
                            prioridade = "Cr√≠tica"
                        elif media < 3.5:
                            prioridade = "Alta"
                        elif media < goal:
                            prioridade = "M√©dia"
                        else:
                            prioridade = "Manuten√ß√£o"
                        relatorio_data['Prioridade'].append(prioridade)
                
                df_relatorio = pd.DataFrame(relatorio_data)
                csv = df_relatorio.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="üì• Download CSV",
                    data=csv,
                    file_name=f"relatorio_portal_transparencia_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )


# -----------------------------
# Page: Configura√ß√µes
# -----------------------------
if page == "Configura√ß√µes":
    st.header("‚öôÔ∏è Configura√ß√µes e Metas")
    st.write("""
    Defina a **meta (goal)** global na barra lateral. 
    Agora voc√™ tamb√©m pode definir metas por dimens√£o e salvar filtros padr√µes.
    """)

    # Metas por dimens√£o (persistentes)
    if st.session_state.auth["logged_in"]:
        user_prefs = st.session_state.dm.get_user_preferences(st.session_state.auth["email"])  # dict
        st.subheader("Metas por Dimens√£o")
        with st.form("form_goals_by_dim"):
            new_goals = {}
            for dim in DIMENSIONS.keys():
                # Ajustar default_val usando dict
                _default_goal_cfg = float(user_prefs.get("goal", user_prefs.get("goal_global", DEFAULT_GOAL))) if isinstance(user_prefs, dict) else DEFAULT_GOAL
                default_val = user_prefs.get("goal_by_dimension", {}).get(dim, _default_goal_cfg) if isinstance(user_prefs, dict) else _default_goal_cfg
                new_goals[dim] = st.number_input(f"Meta para {dim}", min_value=1.0, max_value=5.0, step=0.1, value=float(default_val))
            submitted = st.form_submit_button("Salvar metas por dimens√£o")
            if submitted:
                try:
                    # Substituir constru√ß√£o de UserPreferences por dict
                    updated = dict(user_prefs or {}) if isinstance(user_prefs, dict) else {}
                    updated["goal_by_dimension"] = {k: float(v) for k, v in new_goals.items()}
                    st.session_state.dm.save_user_preferences(st.session_state.auth["email"], updated)
                    st.success("Metas por dimens√£o salvas.")
                except Exception as e:
                    st.error(f"Falha ao salvar metas: {e}")

        st.subheader("Prefer√™ncias de Filtros")
        st.caption("Os filtros selecionados na sidebar s√£o salvos automaticamente por usu√°rio.")
    else:
        st.info("Fa√ßa login para salvar metas por dimens√£o e filtros padr√£o.")

    st.write("### Mapeamento de Itens por Dimens√£o")
    st.json(DIMENSIONS, expanded=False)

    st.write("### Ordem e Mapeamento Likert")
    col1, col2 = st.columns(2)
    with col1:
        st.json(LIKERT_ORDER, expanded=False)
    with col2:
        st.json(LIKERT_MAP, expanded=False)

    st.write("### Campo de Satisfa√ß√£o e Mapeamento")
    st.write(f"Campo de satisfa√ß√£o: **{SAT_FIELD}**")
    st.json(SAT_MAP, expanded=False)

    st.write("### Campos de Perfil")
    st.json(PROFILE_FIELDS, expanded=False)
