#!/usr/bin/env python3
"""
Script para prÃ©-processar o arquivo basetransp.csv
Converte respostas Likert em valores numÃ©ricos e calcula mÃ©dias por linha
"""

import os
import pandas as pd
import numpy as np
import json

def load_mapping():
    """Carrega o mapeamento de configuraÃ§Ã£o"""
    with open(os.path.join("config", "items_mapping.json"), "r", encoding="utf-8") as f:
        return json.load(f)

def normalize_likert_value(value, likert_map):
    """Converte um valor Likert individual em numÃ©rico"""
    if pd.isna(value) or value == "" or value is None:
        return np.nan
    
    # Limpar o valor (remover espaÃ§os extras)
    value = str(value).strip()
    
    # Mapear para valor numÃ©rico
    return likert_map.get(value, np.nan)

def preprocess_basetransp():
    """Processa o arquivo basetransp.csv"""
    
    # Carregar configuraÃ§Ãµes
    mapping = load_mapping()
    
    # Obter mapeamento para 8 questÃµes
    if "8 questÃµes" in mapping:
        config_8q = mapping["8 questÃµes"]
        dimensions = config_8q["dimensions"]
        likert_map = config_8q["likert_map"]
    else:
        # Fallback para configuraÃ§Ã£o padrÃ£o
        dimensions = mapping["dimensions"]
        likert_map = mapping["likert_map"]
    
    print("ğŸ“Š Mapeamento Likert:")
    for key, value in likert_map.items():
        print(f"  {key} â†’ {value}")
    print()
    
    # Carregar arquivo original
    input_file = os.path.join("data", "basetransp.csv")
    if not os.path.exists(input_file):
        input_file = os.path.join("sample_data", "basetransp.csv")
    
    print(f"ğŸ“‚ Carregando arquivo: {input_file}")
    
    try:
        df = pd.read_csv(input_file, sep=";", encoding="latin-1")
        print(f"âœ… Arquivo carregado: {len(df)} linhas, {len(df.columns)} colunas")
    except Exception as e:
        print(f"âŒ Erro ao carregar arquivo: {e}")
        return
    
    # Mostrar primeiras linhas originais
    print("\nğŸ“‹ Primeiras 3 linhas originais:")
    print(df.head(3).to_string())
    
    # Identificar colunas de questÃµes e colunas de perfil
    profile_fields = ["Idade", "Escolaridade", "Renda", "Sexo", "SatisfaÃ§Ã£o"]
    question_columns = []
    profile_columns = []
    
    for col in df.columns:
        if col in profile_fields:
            profile_columns.append(col)
        else:
            # Verificar se contÃ©m respostas Likert
            unique_vals = df[col].dropna().unique()
            likert_found = any(str(val).strip() in likert_map for val in unique_vals if pd.notna(val))
            if likert_found:
                question_columns.append(col)
            else:
                profile_columns.append(col)
    
    print(f"\nğŸ” Colunas de questÃµes identificadas: {len(question_columns)}")
    for i, col in enumerate(question_columns, 1):
        print(f"  {i}. {col}")
    
    print(f"\nğŸ‘¤ Colunas de perfil identificadas: {len(profile_columns)}")
    for i, col in enumerate(profile_columns, 1):
        print(f"  {i}. {col}")
    
    # Criar DataFrame processado
    df_processed = df.copy()
    
    # Converter cada coluna de questÃ£o
    print("\nğŸ”„ Convertendo respostas Likert para valores numÃ©ricos...")
    conversion_stats = {}
    
    for col in question_columns:
        if col in df.columns:
            original_values = df[col].value_counts(dropna=False)
            print(f"\nğŸ“Š Coluna: {col}")
            print("  Valores originais:")
            for val, count in original_values.items():
                print(f"    {val}: {count}")
            
            # Aplicar conversÃ£o
            df_processed[col] = df[col].apply(lambda x: normalize_likert_value(x, likert_map))
            
            # EstatÃ­sticas da conversÃ£o
            converted_values = df_processed[col].value_counts(dropna=False)
            print("  Valores convertidos:")
            for val, count in converted_values.items():
                print(f"    {val}: {count}")
            
            conversion_stats[col] = {
                'original_unique': len(original_values),
                'converted_unique': len(converted_values),
                'null_count': df_processed[col].isna().sum()
            }
    
    # Mostrar estatÃ­sticas dos dados de perfil preservados
    print(f"\nğŸ‘¤ Resumo dos dados de perfil preservados:")
    for col in profile_columns:
        if col in df_processed.columns:
            non_null = df_processed[col].count()
            total = len(df_processed)
            print(f"  - {col}: {non_null}/{total} valores nÃ£o-nulos ({non_null/total*100:.1f}%)")
    
    # Calcular mÃ©dias por linha (apenas para colunas de questÃµes)
    print("\nğŸ“ˆ Calculando mÃ©dias por linha...")
    numeric_columns = [col for col in question_columns if col in df_processed.columns]
    
    # Calcular mÃ©dia ignorando valores NaN
    df_processed['Media_Respostas'] = df_processed[numeric_columns].mean(axis=1, skipna=True)
    
    # Calcular nÃºmero de respostas vÃ¡lidas por linha
    df_processed['Num_Respostas_Validas'] = df_processed[numeric_columns].notna().sum(axis=1)
    
    # Mostrar estatÃ­sticas das mÃ©dias
    print(f"ğŸ“Š EstatÃ­sticas das mÃ©dias calculadas:")
    print(f"  MÃ©dia geral: {df_processed['Media_Respostas'].mean():.2f}")
    print(f"  Mediana: {df_processed['Media_Respostas'].median():.2f}")
    print(f"  Desvio padrÃ£o: {df_processed['Media_Respostas'].std():.2f}")
    print(f"  MÃ­nimo: {df_processed['Media_Respostas'].min():.2f}")
    print(f"  MÃ¡ximo: {df_processed['Media_Respostas'].max():.2f}")
    
    # Mostrar distribuiÃ§Ã£o de respostas vÃ¡lidas
    print(f"\nğŸ“Š DistribuiÃ§Ã£o de respostas vÃ¡lidas por linha:")
    valid_counts = df_processed['Num_Respostas_Validas'].value_counts().sort_index()
    for count, freq in valid_counts.items():
        print(f"  {count} respostas: {freq} linhas")
    
    # Mostrar primeiras linhas processadas
    print("\nğŸ“‹ Primeiras 3 linhas processadas:")
    display_cols = numeric_columns[:3] + profile_columns[:2] + ['Media_Respostas', 'Num_Respostas_Validas']
    # Filtrar apenas colunas que existem
    display_cols = [col for col in display_cols if col in df_processed.columns]
    print(df_processed[display_cols].head(3).to_string())
    
    # Salvar arquivo processado
    output_file = os.path.join("data", "basetransp_processado.csv")
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    try:
        df_processed.to_csv(output_file, sep=";", encoding="latin-1", index=False)
        print(f"\nâœ… Arquivo processado salvo: {output_file}")
        print(f"   Linhas: {len(df_processed)}, Colunas: {len(df_processed.columns)}")
    except Exception as e:
        print(f"âŒ Erro ao salvar arquivo: {e}")
        return
    
    # Criar relatÃ³rio de conversÃ£o
    print("\nğŸ“‹ RelatÃ³rio de ConversÃ£o:")
    print("=" * 50)
    for col, stats in conversion_stats.items():
        print(f"Coluna: {col}")
        print(f"  Valores Ãºnicos originais: {stats['original_unique']}")
        print(f"  Valores Ãºnicos convertidos: {stats['converted_unique']}")
        print(f"  Valores nulos: {stats['null_count']}")
        print()
    
    print("ğŸ‰ Processamento concluÃ­do com sucesso!")
    print(f"ğŸ“ Arquivo original: {input_file}")
    print(f"ğŸ“ Arquivo processado: {output_file}")

if __name__ == "__main__":
    preprocess_basetransp()